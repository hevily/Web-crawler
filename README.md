# comadd
get the addresses of companies 

一、项目基本情况
    手头有份数据量大约8万的公司名单，客户需求是从百度企业信用、企查查等网站获取公司注册地址信息。
    对比了企查查、阿里企业黄页等网站，敲定使用百度企业信用作为爬虫对象。
    
    百度企业信用网站，有一些反爬虫机制。如连续访问8次需要输入一次验证码，同一个IP连续72次会被禁止访问半天。
    因此本项目建立了代理IP池等方式进行反反爬虫。
 
 
 
 二、项目策略
 
 
 1.反“反爬虫”策略
 
 
 
 （1）输入验证码:
 
 
      1）调用Selenium库进行截屏、获取验证码图片并保存至本地；
      
      
	  2）调用云打码平台：识别验证码，返回文字形式的验证码
      
      
      
（2）封IP：构建IP代理池

     1）获取免费IP地址：对比西刺、站大爷等多个免费代理IP网站，最终选定可用IP较多的免费代理网站（http://ip.jiangxianli.com/）

     2）使用urllib获取网页内容，提取网页内容中的IP和端口信息。
     
     3）由于免费IP不稳定性较高，可用的时效性短，因此每次爬虫仅爬前5个页面。
     
     4）验证IP是否可用：第一次验证IP可用性，使用urllib访问百度首页，将可用的IP存储于本地；用经第一次验证后可用的IP进行第二次验证，调用Selenium 打开百度企业信用首页，将可用的IP存储于本地
 
 
 
 
 三、文件说明：
 
 getidadd.py------从免费代理IP网站获取IP地址及端口号，并验证IP是否可用，将可用的IP存储到本地文件。先运行
 getcomadd.py-----从百度企业信用网站提取地址信息，将地址信息存储于本地。
    
